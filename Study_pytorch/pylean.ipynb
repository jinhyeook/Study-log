{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b85be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능? True\n",
      "GPU 이름 : NVIDIA GeForce GTX 1660 SUPER\n",
      "GPU 개수 : 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA 사용 가능?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 이름 : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 개수 : {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d06906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([1,2,3]))\n",
    "print(torch.tensor([[1,2,3], [4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1acef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "print(tensor.dtype)\n",
    "print(tensor.shape)\n",
    "print(tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70285cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 전 : tensor([1, 2, 3])\n",
      "변환 후 : tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(f\"변환 전 : {tensor}\")\n",
    "\n",
    "tensor = tensor.reshape(3,1)\n",
    "print(f\"변환 후 : {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b816ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7120, 0.5545, 0.9989],\n",
      "        [0.7726, 0.1740, 0.5142],\n",
      "        [0.1488, 0.0635, 0.7141]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand((3,3), dtype=torch.float)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0bb5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimji\\AppData\\Local\\Temp\\ipykernel_26244\\3882855782.py:5: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:80.)\n",
      "  gpu = torch.cuda.FloatTensor([1,2,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "tensor([[0.0856, 0.6452, 0.7610],\n",
      "        [0.0134, 0.6113, 0.9309],\n",
      "        [0.5335, 0.5456, 0.7695]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gpu = torch.cuda.FloatTensor([1,2,3])\n",
    "tensor = torch.rand((3,3), device=device)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d428a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "cpu = torch.FloatTensor([1,2,3])\n",
    "gpu = cpu.cuda()\n",
    "gpuTocpu = gpu.cpu()\n",
    "cpuTogpu = gpuTocpu.to(\"cuda\")\n",
    "\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(gpuTocpu)\n",
    "print(cpuTogpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f80de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "ndarray = np.array([1,2,3], dtype=np.uint8)\n",
    "print(torch.tensor(ndarray))\n",
    "print(torch.Tensor(ndarray))\n",
    "print(torch.from_numpy(ndarray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e098e134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pytorch\n",
    "import numpy as np\n",
    "\n",
    "tensor = torch.cuda.FloatTensor([1,2,3])\n",
    "ndarray = tensor.detach().cpu().numpy()\n",
    "print(ndarray)\n",
    "print(type(ndarray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ca5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
